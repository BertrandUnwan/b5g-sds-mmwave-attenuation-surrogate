{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa83c98e",
   "metadata": {},
   "source": [
    "# Aerosol–Meteorology Data Fusion\n",
    "\n",
    "This notebook merges MERRA-2 aerosol diagnostics and near-surface meteorological fields into a single, spatiotemporally aligned dataset over Saudi Arabia (2012–2021).\n",
    "\n",
    "Both components have been independently validated in prior EDA notebooks to ensure:\n",
    "- variable presence and integrity,\n",
    "- physically reasonable ranges,\n",
    "- absence of encoded fill values,\n",
    "- consistent spatial and temporal grids.\n",
    "\n",
    "The objective here is to construct a clean, unified dataset suitable for feature engineering and supervised learning of SDS-induced mmWave attenuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9908a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# Standard library\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe026aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project paths (robust to execution location)\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "AER_DIR = ROOT / \"data\" / \"raw\" / \"merra2\" / \"aer\" / \"2012_2021\"\n",
    "MET_DIR = ROOT / \"data\" / \"raw\" / \"merra2\" / \"met\" / \"2012_2021\"\n",
    "\n",
    "OUT_DIR = ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"AER_DIR:\", AER_DIR, \"| exists:\", AER_DIR.exists())\n",
    "print(\"MET_DIR:\", MET_DIR, \"| exists:\", MET_DIR.exists())\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "\n",
    "# ---- Run mode ----\n",
    "# \"sample\" = merge only the first aer+met files (fast debug)\n",
    "# \"full\"   = merge ALL matching aer+met files and write full artifact\n",
    "RUN_MODE = \"full\"  # change to \"sample\" for quick tests\n",
    "\n",
    "# Output filenames\n",
    "OUT_FP_SAMPLE = OUT_DIR / \"merged_rep_sample_20120101.nc4\"\n",
    "OUT_FP_FULL = OUT_DIR / \"merged_full_2012_2021.nc4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb10ac",
   "metadata": {},
   "source": [
    "## Merge Strategy\n",
    "\n",
    "The aerosol and meteorological datasets share:\n",
    "- identical latitude–longitude grids,\n",
    "- hourly temporal resolution,\n",
    "- consistent CF-compliant metadata.\n",
    "\n",
    "The merge strategy is therefore:\n",
    "- load both datasets lazily with xarray,\n",
    "- align explicitly on time, latitude, and longitude,\n",
    "- subset to common timestamps,\n",
    "- retain only variables required for downstream modeling.\n",
    "\n",
    "No spatial interpolation or temporal resampling is performed at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aerosol variables (from EDA)\n",
    "aer_vars = [\n",
    "    \"DUCMASS\",\n",
    "    \"DUCMASS25\",\n",
    "    \"DUSMASS\",\n",
    "    \"DUSMASS25\",\n",
    "    \"DUEXTTAU\",\n",
    "    \"DUSCATAU\",\n",
    "    \"DUANGSTR\",\n",
    "]\n",
    "\n",
    "# Meteorological variables (from EDA)\n",
    "met_vars = [\n",
    "    \"T2M\",\n",
    "    \"U2M\",\n",
    "    \"V2M\",\n",
    "    \"U10M\",\n",
    "    \"V10M\",\n",
    "    \"PS\",\n",
    "    \"SLP\",\n",
    "    \"QV2M\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80683c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover files (robust to nested folders + .nc/.nc4)\n",
    "aer_files = sorted(AER_DIR.rglob(\"*.nc\")) + sorted(AER_DIR.rglob(\"*.nc4\"))\n",
    "met_files = sorted(MET_DIR.rglob(\"*.nc\")) + sorted(MET_DIR.rglob(\"*.nc4\"))\n",
    "\n",
    "print(\"Aerosol files found:\", len(aer_files))\n",
    "print(\"Met files found:\", len(met_files))\n",
    "\n",
    "if not aer_files:\n",
    "    raise FileNotFoundError(f\"No aerosol NetCDF files found under {AER_DIR}\")\n",
    "if not met_files:\n",
    "    raise FileNotFoundError(f\"No meteorological NetCDF files found under {MET_DIR}\")\n",
    "\n",
    "# Helper: extract YYYYMMDD from filename to pair aer/met files\n",
    "# Your raw files are daily (e.g., ...Nx.20120101_subsetted.nc4), so we must pair by day.\n",
    "import re\n",
    "\n",
    "def _key_yyyymmdd(p: Path) -> str | None:\n",
    "    m = re.search(r\"(20\\d{2})(0[1-9]|1[0-2])([0-3]\\d)\", p.name)\n",
    "    if m:\n",
    "        return f\"{m.group(1)}{m.group(2)}{m.group(3)}\"\n",
    "    return None\n",
    "\n",
    "# Build maps for pairing\n",
    "_aer_map = {}\n",
    "for p in aer_files:\n",
    "    k = _key_yyyymmdd(p)\n",
    "    if k is not None and k not in _aer_map:\n",
    "        _aer_map[k] = p\n",
    "\n",
    "_met_map = {}\n",
    "for p in met_files:\n",
    "    k = _key_yyyymmdd(p)\n",
    "    if k is not None and k not in _met_map:\n",
    "        _met_map[k] = p\n",
    "\n",
    "common_keys = sorted(set(_aer_map) & set(_met_map))\n",
    "\n",
    "print(\"Pairable YYYYMMDD keys:\", len(common_keys))\n",
    "if not common_keys:\n",
    "    # Fallback: if filenames don't contain YYYYMMDD, just pair by sorted order\n",
    "    print(\"[WARN] Could not detect YYYYMMDD in filenames; falling back to index-wise pairing.\")\n",
    "    n = min(len(aer_files), len(met_files))\n",
    "    common_pairs = list(zip(aer_files[:n], met_files[:n]))\n",
    "else:\n",
    "    common_pairs = [(_aer_map[k], _met_map[k]) for k in common_keys]\n",
    "\n",
    "# In sample mode, keep only the first pair\n",
    "if RUN_MODE == \"sample\":\n",
    "    common_pairs = common_pairs[:1]\n",
    "    print(\"RUN_MODE=sample -> using only 1 aer/met pair\")\n",
    "else:\n",
    "    print(\"RUN_MODE=full -> using\", len(common_pairs), \"aer/met pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00595487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Merge pipeline ===\")\n",
    "\n",
    "merged_parts: list[Path] = []\n",
    "\n",
    "# Write per-pair merged parts first (keeps memory stable)\n",
    "parts_dir = OUT_DIR / \"_merge_parts\"\n",
    "parts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, (a_fp, m_fp) in enumerate(common_pairs, start=1):\n",
    "    print(f\"[{i}/{len(common_pairs)}] AER={a_fp.name} | MET={m_fp.name}\")\n",
    "\n",
    "    ds_aer = xr.open_dataset(a_fp, engine=\"netcdf4\")[aer_vars]\n",
    "    ds_met = xr.open_dataset(m_fp, engine=\"netcdf4\")[met_vars]\n",
    "\n",
    "    # Alignment checks (require exact coords)\n",
    "    if not np.array_equal(ds_aer[\"lat\"].values, ds_met[\"lat\"].values):\n",
    "        raise ValueError(f\"lat mismatch for {a_fp.name} vs {m_fp.name}\")\n",
    "    if not np.array_equal(ds_aer[\"lon\"].values, ds_met[\"lon\"].values):\n",
    "        raise ValueError(f\"lon mismatch for {a_fp.name} vs {m_fp.name}\")\n",
    "    if not np.array_equal(ds_aer[\"time\"].values, ds_met[\"time\"].values):\n",
    "        raise ValueError(f\"time mismatch for {a_fp.name} vs {m_fp.name}\")\n",
    "\n",
    "    ds_merged = xr.merge([ds_aer, ds_met], compat=\"identical\", join=\"exact\")\n",
    "\n",
    "    # Quick missingness check on this part\n",
    "    part_missing = float(ds_merged.to_array().isnull().mean())\n",
    "    print(f\"    missing fraction (part): {part_missing:.6f}\")\n",
    "\n",
    "    # Save part\n",
    "    # Use key if available; else fall back to index\n",
    "    k = _key_yyyymmdd(a_fp) or f\"part_{i:04d}\"\n",
    "    part_fp = parts_dir / f\"merged_{k}.nc4\"\n",
    "    ds_merged.to_netcdf(part_fp, engine=\"netcdf4\")\n",
    "    merged_parts.append(part_fp)\n",
    "\n",
    "# Final assembly\n",
    "if RUN_MODE == \"sample\":\n",
    "    # For sample mode, also save a stable sample artifact name\n",
    "    final_fp = OUT_FP_SAMPLE\n",
    "    ds_final = xr.open_dataset(merged_parts[0], engine=\"netcdf4\")\n",
    "    ds_final.to_netcdf(final_fp, engine=\"netcdf4\")\n",
    "    print(\"Saved merged representative sample to:\", final_fp)\n",
    "else:\n",
    "    final_fp = OUT_FP_FULL\n",
    "\n",
    "    print(\"=== Concatenating parts into full dataset ===\")\n",
    "    ds_final = xr.open_mfdataset(\n",
    "        [str(p) for p in merged_parts],\n",
    "        engine=\"netcdf4\",\n",
    "        combine=\"by_coords\",\n",
    "        parallel=False,\n",
    "    )\n",
    "\n",
    "    # Global missingness check\n",
    "    missing_frac = float(ds_final.to_array().isnull().mean())\n",
    "    print(f\"Overall missing fraction (full): {missing_frac:.6f}\")\n",
    "\n",
    "    ds_final.to_netcdf(final_fp, engine=\"netcdf4\")\n",
    "    print(\"Saved FULL merged dataset to:\", final_fp)\n",
    "\n",
    "print(\"DONE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004715f4",
   "metadata": {},
   "source": [
    "## Merge Outcome Summary\n",
    "\n",
    "This notebook completed the full fusion of MERRA-2 aerosol and near-surface meteorological diagnostics into a single, spatiotemporally aligned dataset spanning the complete 2012–2021 study period.\n",
    "\n",
    "### Key Outcomes\n",
    "\n",
    "- Aerosol (M2T1NXAER) and meteorological (M2T1NXSLV) datasets are perfectly aligned by:\n",
    "  - Time (daily resolution)\n",
    "  - Latitude\n",
    "  - Longitude\n",
    "- Pairing is performed at the **daily level (YYYYMMDD)** to ensure exact temporal correspondence.\n",
    "- All selected aerosol and meteorological variables are preserved without resampling or interpolation.\n",
    "- Strict coordinate equality checks enforce:\n",
    "  - No spatial misalignment\n",
    "  - No temporal drift\n",
    "- Missingness was verified at both per-part and global levels.\n",
    "- The final merged artifact was saved as: `data/processed/merged_full_2012_2021.nc4`\n",
    "\n",
    "### Engineering Design Decisions\n",
    "\n",
    "- Merging is performed per daily file and written as intermediate parts to maintain memory stability.\n",
    "- Final concatenation is executed using `xarray.open_mfdataset` with coordinate-based alignment.\n",
    "- The merged dataset retains the native spatial resolution and temporal sampling of MERRA-2.\n",
    "\n",
    "### Role in the Pipeline\n",
    "\n",
    "This merged dataset is the canonical upstream artifact for:\n",
    "\n",
    "- Feature engineering\n",
    "- Physics-informed label construction\n",
    "- Saudi-calibrated attenuation generation\n",
    "- Surrogate model training and validation\n",
    "\n",
    "All downstream stages depend exclusively on this artifact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
